{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Programy\\Anaconda\\envs\\Z_NEW_ORDER\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.preprocessing import image\n",
    "#from keras.engine import Layer\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Input, Reshape, concatenate\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers import RepeatVector, Permute\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.callbacks import TensorBoard \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "#from keras.layers.core import RepeatVector, Permute\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray, gray2rgb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import onnx\n",
    "#import keras2onnx\n",
    "import os\n",
    "import random\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n07749582_lemon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     image_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marray(image_data, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image_data\n\u001b[1;32m---> 13\u001b[0m train_images_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages//Train_original//\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m category \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_all//\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mn07749582_lemon\u001b[49m\n\u001b[0;32m     14\u001b[0m valid_images_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages//Valid//\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m category \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_all//\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m subcategory\n\u001b[0;32m     15\u001b[0m Xtrain \u001b[38;5;241m=\u001b[39m load_images_from_directory(train_images_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n07749582_lemon' is not defined"
     ]
    }
   ],
   "source": [
    "category='Plant'\n",
    "subcategory='lemon'\n",
    "\n",
    "def load_images_from_directory(directory_path):\n",
    "    image_data = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        img = load_img(os.path.join(directory_path, filename))\n",
    "        img_array = img_to_array(img)\n",
    "        image_data.append(img_array)\n",
    "    image_data = 1.0/255 * np.array(image_data, dtype=float)\n",
    "    return image_data\n",
    "\n",
    "train_images_path = 'images//Train_original//' + category + '_all//' + \"n07749582_lemon\"\n",
    "valid_images_path = 'images//Valid//' + category + '_all//' + subcategory\n",
    "Xtrain = load_images_from_directory(train_images_path)\n",
    "Xvalid = load_images_from_directory(valid_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Encoder\n",
    "encoder_input = Input(shape=(256, 256, 1))\n",
    "encoder_output = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\n",
    "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_output)\n",
    "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "\n",
    "\n",
    "#Decoder\n",
    "decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "decoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\n",
    "decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
    "decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
    "\n",
    "\n",
    "#model = Model(inputs=encoder_input, outputs=decoder_output)\n",
    "model = keras.models.load_model(os.path.join(os.getcwd(), \"models/models_h5/without_fusion/best_model_lemon_500.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Image transformer\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.4,\n",
    "        zoom_range=0.4,\n",
    "        rotation_range=40,\n",
    "        horizontal_flip=True,\n",
    "        preprocessing_function=tf.keras.layers.RandomCrop(256,256)\n",
    ")\n",
    "\n",
    "#Generate training data\n",
    "batch_size = 50\n",
    "\n",
    "# EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=125, restore_best_weights=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint('models/models_h5/without_fusion/best_model_' + subcategory + '_500_CROP.h5', monitor='val_loss', \n",
    "                             save_best_only=True)\n",
    "def image_a_b_gen(batch_size):\n",
    "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
    "        grayscaled_rgb = gray2rgb(rgb2gray(batch))\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        X_batch = lab_batch[:,:,:,0]\n",
    "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "        yield X_batch, Y_batch\n",
    "\n",
    "# Create a separate generator for validation data\n",
    "def validation_gen(batch_size):\n",
    "    for batch in datagen.flow(Xvalid, batch_size=batch_size):\n",
    "        grayscaled_rgb = gray2rgb(rgb2gray(batch))\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        X_batch = lab_batch[:, :, :, 0]\n",
    "        X_batch = X_batch.reshape(X_batch.shape + (1,))\n",
    "        Y_batch = lab_batch[:, :, :, 1:] / 128\n",
    "        yield (X_batch, Y_batch)\n",
    "\n",
    "# Train model with validation data\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "hist = model.fit(\n",
    "    image_a_b_gen(batch_size),\n",
    "    steps_per_epoch=len(Xtrain) // batch_size,\n",
    "    epochs=1000,\n",
    "    validation_data=validation_gen(batch_size),\n",
    "    validation_steps=len(Xvalid) // batch_size,\n",
    "    callbacks=[early_stopping, checkpoint])\n",
    "\n",
    "#model.fit_generator(\n",
    "#    image_a_b_gen(batch_size),\n",
    "#    epochs=7500,\n",
    "#    steps_per_epoch=len(Xtrain) // batch_size,\n",
    "#    validation_data=validation_gen(batch_size),\n",
    "#    validation_steps=len(Xvalid) // batch_size,\n",
    "#    callbacks=[early_stopping, checkpoint])  # Dodaj ModelCheckpoint do listy callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import keras2onnx\n",
    "\n",
    "model.save(os.path.join(os.getcwd(), 'models/models_h5/without_fusion/' + subcategory + '_500_CROP.h5'))\n",
    "\n",
    "# Konwersja modelu na format ONNX\n",
    "onnx_model = keras2onnx.convert_keras(model)\n",
    "\n",
    "# Zapis modelu ONNX do pliku\n",
    "onnx.save_model(onnx_model, os.path.join(os.getcwd(), 'models/models_onnx/without_fusion/' + subcategory + '_500_CROP.onnx'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist_df = pd.DataFrame(hist.history) \n",
    "\n",
    "hist_csv_file = 'history_' + subcategory + '.csv'\n",
    "with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
